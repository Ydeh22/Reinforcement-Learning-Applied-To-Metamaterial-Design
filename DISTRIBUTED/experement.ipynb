{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.agents.ddpg import apex\n",
    "from ray.rllib.agents import impala\n",
    "from ray import tune\n",
    "import gym\n",
    "import torch\n",
    "from env import DistributedTSCSEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = impala.DEFAULT_CONFIG.copy()\n",
    "config['rollout_fragment_length'] = 100\n",
    "config['train_batch_size'] = 500\n",
    "config['num_workers'] = 2\n",
    "config['num_gpus'] = 1\n",
    "config['framework'] = 'torch'\n",
    "config['gamma'] = 0.90\n",
    "config['env'] = DistributedTSCSEnv\n",
    "config['env_config'] = {\n",
    "    'nCyl': 4,\n",
    "    'k0amax': 0.45,\n",
    "    'k0amin': 0.35,\n",
    "    'nFreq': 11,\n",
    "    'actionRange': 0.5,\n",
    "    'episodeLength': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 15:09:26,978\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.0.12',\n",
       " 'raylet_ip_address': '10.0.0.12',\n",
       " 'redis_address': '10.0.0.12:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-03_15-09-26_489625_245789/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-03_15-09-26_489625_245789/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-03_15-09-26_489625_245789',\n",
       " 'metrics_export_port': 45258}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=245938)\u001b[0m /home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=245938)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=245940)\u001b[0m /home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=245940)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    }
   ],
   "source": [
    "agent = impala.ImpalaTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-03 15:12:10,965\tINFO ray_trial_executor.py:170 -- Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`.\n",
      "2020-11-03 15:12:11,571\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 5.2/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+-------+\n",
      "| Trial name                            | status   | loc   |\n",
      "|---------------------------------------+----------+-------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  |       |\n",
      "+---------------------------------------+----------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=252091)\u001b[0m 2020-11-03 15:12:13,848\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=252091)\u001b[0m Warning: Name is nonexistent or not a directory: /home/tristan/ray_results/IMPALA/IMPALA_DistributedTSCSEnv_dbf51_00000_0_2020-11-03_15-12-12/../DDPG/TSCS\n",
      "\u001b[2m\u001b[36m(pid=252091)\u001b[0m > In path (line 109)\n",
      "\u001b[2m\u001b[36m(pid=252091)\u001b[0m In addpath (line 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=252100)\u001b[0m /home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=252100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=252097)\u001b[0m /home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=252097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -147.87286259528258\n",
      "  episode_reward_mean: -166.3951033860856\n",
      "  episode_reward_min: -205.54194001597696\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 10\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5621.1318359375\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 29435.123046875\n",
      "        model: {}\n",
      "        policy_loss: -84710.90625\n",
      "        var_gnorm: 22.650083541870117\n",
      "        vf_explained_var:\n",
      "        - -0.08449208736419678\n",
      "        vf_loss: 58451.5234375\n",
      "    learner_queue:\n",
      "      size_count: 1\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 600\n",
      "    num_steps_trained: 500\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 15201.108\n",
      "      learner_grad_time_ms: 193.563\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.64516129032259\n",
      "    gpu_util_percent0: 0.013548387096774195\n",
      "    ram_util_percent: 36.18387096774194\n",
      "    vram_util_percent0: 0.22859949555290054\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14229924854880083\n",
      "    mean_env_wait_ms: 43.72391301000903\n",
      "    mean_inference_ms: 1.5680283129572157\n",
      "    mean_raw_obs_processing_ms: 0.5494572683246788\n",
      "  time_since_restore: 23.110883474349976\n",
      "  time_this_iter_s: 23.110883474349976\n",
      "  time_total_s: 23.110883474349976\n",
      "  timers:\n",
      "    sample_throughput: 33.001\n",
      "    sample_time_ms: 15151.111\n",
      "  timestamp: 1604434363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600\n",
      "  training_iteration: 1\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.6/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      1 |          23.1109 |  600 | -166.395 |             -147.873 |             -205.542 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-13-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -171.78764593831917\n",
      "  episode_reward_min: -236.22347820449738\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 19\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5596.2060546875\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 24366.669921875\n",
      "        model: {}\n",
      "        policy_loss: -56385.921875\n",
      "        var_gnorm: 22.65198516845703\n",
      "        vf_explained_var:\n",
      "        - 0.13016414642333984\n",
      "        vf_loss: 28591.84765625\n",
      "    learner_queue:\n",
      "      size_count: 3\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 1500\n",
      "    num_steps_trained: 1500\n",
      "    num_weight_broadcasts: 2\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11641.619\n",
      "      learner_grad_time_ms: 81.39\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.52222222222222\n",
      "    gpu_util_percent0: 0.015925925925925927\n",
      "    ram_util_percent: 36.79999999999999\n",
      "    vram_util_percent0: 0.235281207133059\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14135843119760805\n",
      "    mean_env_wait_ms: 42.347103919251765\n",
      "    mean_inference_ms: 1.5563279518825315\n",
      "    mean_raw_obs_processing_ms: 0.5489233500971624\n",
      "  time_since_restore: 43.00409150123596\n",
      "  time_this_iter_s: 19.893208026885986\n",
      "  time_total_s: 43.00409150123596\n",
      "  timers:\n",
      "    sample_throughput: 42.749\n",
      "    sample_time_ms: 11696.132\n",
      "  timestamp: 1604434383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500\n",
      "  training_iteration: 2\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      2 |          43.0041 | 1500 | -171.788 |             -146.918 |             -236.223 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -174.64715039785617\n",
      "  episode_reward_min: -236.22347820449738\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 25\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5589.5244140625\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 20555.783203125\n",
      "        model: {}\n",
      "        policy_loss: -50810.03125\n",
      "        var_gnorm: 22.653392791748047\n",
      "        vf_explained_var:\n",
      "        - 0.014828801155090332\n",
      "        vf_loss: 22129.80078125\n",
      "    learner_queue:\n",
      "      size_count: 4\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 2100\n",
      "    num_steps_trained: 2000\n",
      "    num_weight_broadcasts: 3\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11715.646\n",
      "      learner_grad_time_ms: 68.485\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.65\n",
      "    gpu_util_percent0: 0.026875\n",
      "    ram_util_percent: 36.80625\n",
      "    vram_util_percent0: 0.23522633744855967\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1408103207782494\n",
      "    mean_env_wait_ms: 41.78762826036664\n",
      "    mean_inference_ms: 1.5517322129596718\n",
      "    mean_raw_obs_processing_ms: 0.5485305387989461\n",
      "  time_since_restore: 54.94633769989014\n",
      "  time_this_iter_s: 11.942246198654175\n",
      "  time_total_s: 54.94633769989014\n",
      "  timers:\n",
      "    sample_throughput: 42.511\n",
      "    sample_time_ms: 11761.531\n",
      "  timestamp: 1604434395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2100\n",
      "  training_iteration: 3\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      3 |          54.9463 | 2100 | -174.647 |             -146.918 |             -236.223 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-13-35\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -176.9483701352619\n",
      "  episode_reward_min: -249.83773031180178\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 34\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5595.3837890625\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 25194.373046875\n",
      "        model: {}\n",
      "        policy_loss: -53167.3046875\n",
      "        var_gnorm: 22.657318115234375\n",
      "        vf_explained_var:\n",
      "        - 0.06019777059555054\n",
      "        vf_loss: 25319.1953125\n",
      "    learner_queue:\n",
      "      size_count: 6\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 3000\n",
      "    num_weight_broadcasts: 5\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11176.374\n",
      "      learner_grad_time_ms: 56.792\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.01481481481482\n",
      "    gpu_util_percent0: 0.023333333333333338\n",
      "    ram_util_percent: 36.98888888888889\n",
      "    vram_util_percent0: 0.2355677488187776\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13993516219115132\n",
      "    mean_env_wait_ms: 41.22525324260343\n",
      "    mean_inference_ms: 1.5464008474681497\n",
      "    mean_raw_obs_processing_ms: 0.5475966730062581\n",
      "  time_since_restore: 75.29172921180725\n",
      "  time_this_iter_s: 20.345391511917114\n",
      "  time_total_s: 75.29172921180725\n",
      "  timers:\n",
      "    sample_throughput: 44.579\n",
      "    sample_time_ms: 11216.113\n",
      "  timestamp: 1604434415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 4\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      4 |          75.2917 | 3000 | -176.948 |             -146.918 |             -249.838 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-13-47\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -178.93869799262833\n",
      "  episode_reward_min: -249.83773031180178\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 39\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5586.97509765625\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 23677.759765625\n",
      "        model: {}\n",
      "        policy_loss: -53480.75390625\n",
      "        var_gnorm: 22.659818649291992\n",
      "        vf_explained_var:\n",
      "        - 0.01370096206665039\n",
      "        vf_loss: 24856.220703125\n",
      "    learner_queue:\n",
      "      size_count: 7\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 3500\n",
      "    num_steps_trained: 3500\n",
      "    num_weight_broadcasts: 6\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11309.017\n",
      "      learner_grad_time_ms: 53.719\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.266666666666666\n",
      "    gpu_util_percent0: 0.010666666666666666\n",
      "    ram_util_percent: 37.10000000000001\n",
      "    vram_util_percent0: 0.2349300411522634\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13959114662830205\n",
      "    mean_env_wait_ms: 40.97881145802472\n",
      "    mean_inference_ms: 1.5480419318778975\n",
      "    mean_raw_obs_processing_ms: 0.5463216200429246\n",
      "  time_since_restore: 86.92185139656067\n",
      "  time_this_iter_s: 11.630122184753418\n",
      "  time_total_s: 86.92185139656067\n",
      "  timers:\n",
      "    sample_throughput: 44.063\n",
      "    sample_time_ms: 11347.363\n",
      "  timestamp: 1604434427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3500\n",
      "  training_iteration: 5\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      5 |          86.9219 | 3500 | -178.939 |             -146.918 |             -249.838 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-13-59\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -180.93272668755125\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 44\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5594.419921875\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 22497.634765625\n",
      "        model: {}\n",
      "        policy_loss: -49032.90234375\n",
      "        var_gnorm: 22.662612915039062\n",
      "        vf_explained_var:\n",
      "        - 0.004481077194213867\n",
      "        vf_loss: 20822.6171875\n",
      "    learner_queue:\n",
      "      size_count: 8\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "    num_weight_broadcasts: 7\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11336.212\n",
      "      learner_grad_time_ms: 50.313\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.1625\n",
      "    gpu_util_percent0: 0.0225\n",
      "    ram_util_percent: 37.1\n",
      "    vram_util_percent0: 0.23496913580246914\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13932241195681425\n",
      "    mean_env_wait_ms: 40.76301091294174\n",
      "    mean_inference_ms: 1.5490697238110576\n",
      "    mean_raw_obs_processing_ms: 0.5453951231566125\n",
      "  time_since_restore: 98.60854983329773\n",
      "  time_this_iter_s: 11.68669843673706\n",
      "  time_total_s: 98.60854983329773\n",
      "  timers:\n",
      "    sample_throughput: 43.962\n",
      "    sample_time_ms: 11373.558\n",
      "  timestamp: 1604434439\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 6\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      6 |          98.6085 | 4000 | -180.933 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-14-10\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -181.5646895728974\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 49\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5611.6474609375\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 22863.822265625\n",
      "        model: {}\n",
      "        policy_loss: -46490.84375\n",
      "        var_gnorm: 22.665712356567383\n",
      "        vf_explained_var:\n",
      "        - 0.10384374856948853\n",
      "        vf_loss: 19266.3984375\n",
      "    learner_queue:\n",
      "      size_count: 9\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 4500\n",
      "    num_steps_trained: 4500\n",
      "    num_weight_broadcasts: 8\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11376.63\n",
      "      learner_grad_time_ms: 47.782\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.825\n",
      "    gpu_util_percent0: 0.028124999999999997\n",
      "    ram_util_percent: 37.09375\n",
      "    vram_util_percent0: 0.2348559670781893\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13901989636990197\n",
      "    mean_env_wait_ms: 40.561804073522524\n",
      "    mean_inference_ms: 1.5488064230393188\n",
      "    mean_raw_obs_processing_ms: 0.5441028853693405\n",
      "  time_since_restore: 110.20864915847778\n",
      "  time_this_iter_s: 11.600099325180054\n",
      "  time_total_s: 110.20864915847778\n",
      "  timers:\n",
      "    sample_throughput: 43.813\n",
      "    sample_time_ms: 11412.25\n",
      "  timestamp: 1604434450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4500\n",
      "  training_iteration: 7\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      7 |          110.209 | 4500 | -181.565 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -181.39062326567156\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 54\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5641.7958984375\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 19386.828125\n",
      "        model: {}\n",
      "        policy_loss: -51792.77734375\n",
      "        var_gnorm: 22.66905403137207\n",
      "        vf_explained_var:\n",
      "        - 0.08272898197174072\n",
      "        vf_loss: 22930.05859375\n",
      "    learner_queue:\n",
      "      size_count: 10\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 5000\n",
      "    num_weight_broadcasts: 9\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11407.729\n",
      "      learner_grad_time_ms: 45.47\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.360000000000003\n",
      "    gpu_util_percent0: 0.02533333333333334\n",
      "    ram_util_percent: 37.10000000000001\n",
      "    vram_util_percent0: 0.23497393689986276\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1388155885975731\n",
      "    mean_env_wait_ms: 40.387709634809376\n",
      "    mean_inference_ms: 1.5491760181094578\n",
      "    mean_raw_obs_processing_ms: 0.5429724511572398\n",
      "  time_since_restore: 121.88359355926514\n",
      "  time_this_iter_s: 11.674944400787354\n",
      "  time_total_s: 121.88359355926514\n",
      "  timers:\n",
      "    sample_throughput: 43.698\n",
      "    sample_time_ms: 11442.058\n",
      "  timestamp: 1604434462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 8\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      8 |          121.884 | 5000 | -181.391 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -182.86236977996774\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 60\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5614.8662109375\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 18833.451171875\n",
      "        model: {}\n",
      "        policy_loss: -44401.31640625\n",
      "        var_gnorm: 22.672733306884766\n",
      "        vf_explained_var:\n",
      "        - -0.21471846103668213\n",
      "        vf_loss: 17605.44140625\n",
      "    learner_queue:\n",
      "      size_count: 11\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 5600\n",
      "    num_steps_trained: 5500\n",
      "    num_weight_broadcasts: 10\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11061.563\n",
      "      learner_grad_time_ms: 29.317\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.46875\n",
      "    gpu_util_percent0: 0.0125\n",
      "    ram_util_percent: 37.1\n",
      "    vram_util_percent0: 0.23502057613168725\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13858074851903504\n",
      "    mean_env_wait_ms: 40.1991512404079\n",
      "    mean_inference_ms: 1.5490026563929193\n",
      "    mean_raw_obs_processing_ms: 0.5417399997969908\n",
      "  time_since_restore: 133.68585777282715\n",
      "  time_this_iter_s: 11.802264213562012\n",
      "  time_total_s: 133.68585777282715\n",
      "  timers:\n",
      "    sample_throughput: 45.033\n",
      "    sample_time_ms: 11103.012\n",
      "  timestamp: 1604434474\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5600\n",
      "  training_iteration: 9\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |      9 |          133.686 | 5600 | -182.862 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -184.36227117477955\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 70\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5652.25830078125\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 21991.14453125\n",
      "        model: {}\n",
      "        policy_loss: -44828.90625\n",
      "        var_gnorm: 22.6809139251709\n",
      "        vf_explained_var:\n",
      "        - 0.226282000541687\n",
      "        vf_loss: 18052.61328125\n",
      "    learner_queue:\n",
      "      size_count: 13\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 6600\n",
      "    num_steps_trained: 6500\n",
      "    num_weight_broadcasts: 12\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11052.071\n",
      "      learner_grad_time_ms: 29.529\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.48076923076923\n",
      "    gpu_util_percent0: 0.018076923076923077\n",
      "    ram_util_percent: 37.126923076923084\n",
      "    vram_util_percent0: 0.23615701171256726\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13819851697360544\n",
      "    mean_env_wait_ms: 39.93316295408222\n",
      "    mean_inference_ms: 1.5477100416631562\n",
      "    mean_raw_obs_processing_ms: 0.5403662391761704\n",
      "  time_since_restore: 153.49540281295776\n",
      "  time_this_iter_s: 19.809545040130615\n",
      "  time_total_s: 153.49540281295776\n",
      "  timers:\n",
      "    sample_throughput: 45.14\n",
      "    sample_time_ms: 11076.771\n",
      "  timestamp: 1604434494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6600\n",
      "  training_iteration: 10\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |     10 |          153.495 | 6600 | -184.362 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/execution/learner_thread.py\", line 65, in run\n",
      "    self.step()\n",
      "  File \"/home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/execution/learner_thread.py\", line 69, in step\n",
      "    batch, _ = self.minibatch_buffer.get()\n",
      "  File \"/home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/site-packages/ray/rllib/execution/minibatch_buffer.py\", line 34, in get\n",
      "    self.buffers[self.idx] = self.inqueue.get(timeout=self.timeout)\n",
      "  File \"/home/tristan/anaconda3/envs/TSCSProject/lib/python3.8/queue.py\", line 178, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_DistributedTSCSEnv_dbf51_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-03_15-15-14\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: -146.9176709524434\n",
      "  episode_reward_mean: -186.47151789410825\n",
      "  episode_reward_min: -252.0955941644179\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 79\n",
      "  experiment_id: 9ed8c71346964dbe83b02e50c48fa41a\n",
      "  experiment_tag: '0'\n",
      "  hostname: tristan-AB350-Gaming-3\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        entropy: 5641.9736328125\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 20230.576171875\n",
      "        model: {}\n",
      "        policy_loss: -41168.25390625\n",
      "        var_gnorm: 22.69015121459961\n",
      "        vf_explained_var:\n",
      "        - 0.1283048391342163\n",
      "        vf_loss: 15463.392578125\n",
      "    learner_queue:\n",
      "      size_count: 15\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_steps_sampled: 7500\n",
      "    num_steps_trained: 7500\n",
      "    num_weight_broadcasts: 14\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 11085.95\n",
      "      learner_grad_time_ms: 30.834\n",
      "      learner_load_time_ms: 0.0\n",
      "      learner_load_wait_time_ms: 0.0\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.0.0.12\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.559259259259257\n",
      "    gpu_util_percent0: 0.06333333333333334\n",
      "    ram_util_percent: 37.01111111111111\n",
      "    vram_util_percent0: 0.23654320987654318\n",
      "  pid: 252091\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.137940832493006\n",
      "    mean_env_wait_ms: 39.74784824372848\n",
      "    mean_inference_ms: 1.5468973484478745\n",
      "    mean_raw_obs_processing_ms: 0.5396730637297175\n",
      "  time_since_restore: 173.63239121437073\n",
      "  time_this_iter_s: 20.136988401412964\n",
      "  time_total_s: 173.63239121437073\n",
      "  timers:\n",
      "    sample_throughput: 45.0\n",
      "    sample_time_ms: 11111.12\n",
      "  timestamp: 1604434514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7500\n",
      "  training_iteration: 11\n",
      "  trial_id: dbf51_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 8.7/23.5 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/12 CPUs, 1/1 GPUs, 0.0/11.72 GiB heap, 0.0/4.0 GiB objects (0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/tristan/ray_results/IMPALA\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                            | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "| IMPALA_DistributedTSCSEnv_dbf51_00000 | RUNNING  | 10.0.0.12:252091 |     11 |          173.632 | 7500 | -186.472 |             -146.918 |             -252.096 |                100 |\n",
      "+---------------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tune.run(\n",
    "    impala.ImpalaTrainer,\n",
    "    stop={},\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = apex.APEX_DDPG_DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 5\n",
    "config['num_gpus'] = 1\n",
    "config['rollout_fragment_length'] = 100\n",
    "config['timesteps_per_iteration'] = 2500\n",
    "config['framework'] = 'torch'\n",
    "config['env'] = DistributedTSCSEnv\n",
    "config['env_config'] = {\n",
    "    'nCyl': 4,\n",
    "    'k0amax': 0.45,\n",
    "    'k0amin': 0.35,\n",
    "    'nFreq': 11,\n",
    "    'actionRange': 0.5,\n",
    "    'episodeLength': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = apex.ApexDDPGTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = agent.get_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.model.from_batch({'obs': torch.tensor([state])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
